{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBoe1-tE05iX",
        "outputId": "b4342a53-00e9-4631-9493-1e5df7f056bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns in students_df: Index(['student_id', 'subjects', 'interests'], dtype='object')\n",
            "Head of students_df:\n",
            "   student_id                                subjects  \\\n",
            "0       S001  Mathematics, Physics, Computer Studies   \n",
            "1       S002             English, Kiswahili, History   \n",
            "2       S003         Biology, Chemistry, Agriculture   \n",
            "3       S004    Geography, History, Business Studies   \n",
            "4       S005          Art and Design, Music, English   \n",
            "\n",
            "                                    interests  \n",
            "0           Robotics, Artificial Intelligence  \n",
            "1                    Creative Writing, Poetry  \n",
            "2  Environmental Science, Sustainable Farming  \n",
            "3                   Urban Planning, Economics  \n",
            "4                 Graphic Design, Songwriting  \n",
            "Columns in courses_df: Index(['course_id', 'course_name', 'subjects', 'skills'], dtype='object')\n",
            "Successfully accessed 'subjects' for first row: Mathematics, Physics, Computer Studies\n",
            "\n",
            "Top 15 Most Important Features:\n",
            "                       feature  importance\n",
            "14       subject_overlap_count    0.901424\n",
            "15       subject_overlap_ratio    0.075985\n",
            "45   student_subject_diversity    0.008156\n",
            "22              stem_alignment    0.004043\n",
            "46  student_interest_diversity    0.002899\n",
            "16      interest_skill_overlap    0.001582\n",
            "17        interest_skill_ratio    0.000943\n",
            "18          student_stem_ratio    0.000761\n",
            "3      course_requires_physics    0.000586\n",
            "47      course_subject_breadth    0.000512\n",
            "9      course_requires_english    0.000499\n",
            "2          student_has_physics    0.000445\n",
            "6          student_has_biology    0.000380\n",
            "4        student_has_chemistry    0.000285\n",
            "20           course_stem_ratio    0.000157\n",
            "\n",
            "Recommendations for test student:\n",
            "  Bachelor of Science (Geospatial Information Science With IT): 0.437\n",
            "  Bachelor of Technology (Geoinformation Technology): 0.437\n",
            "  Bachelor of Science (Computer Science): 0.437\n",
            "  Bachelor of Science (Mathematics & Computer Science): 0.437\n",
            "  Bachelor of Science in Computer Science: 0.437\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pickle\n",
        "import logging\n",
        "from typing import List, Dict, Tuple\n",
        "import itertools\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class XGBoostCareerRecommender:\n",
        "    def __init__(self, n_estimators=100, max_depth=6, learning_rate=0.1,\n",
        "                 objective='reg:squarederror', random_state=42):\n",
        "        \"\"\"\n",
        "        Initialize the XGBoost Career Recommender\n",
        "\n",
        "        Args:\n",
        "            n_estimators: Number of boosting rounds\n",
        "            max_depth: Maximum depth of trees\n",
        "            learning_rate: Learning rate\n",
        "            objective: XGBoost objective function\n",
        "            random_state: Random seed for reproducibility\n",
        "        \"\"\"\n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_depth = max_depth\n",
        "        self.learning_rate = learning_rate\n",
        "        self.objective = objective\n",
        "        self.random_state = random_state\n",
        "\n",
        "        self.model = None\n",
        "        self.scaler = StandardScaler()\n",
        "        self.course_encoder = LabelEncoder()\n",
        "        self.feature_names = []\n",
        "\n",
        "    def extract_advanced_features(self, students_df: pd.DataFrame, courses_df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Extract comprehensive features for XGBoost training\n",
        "\n",
        "        Args:\n",
        "            students_df: DataFrame with student information\n",
        "            courses_df: DataFrame with course information\n",
        "\n",
        "        Returns:\n",
        "            DataFrame with engineered features\n",
        "        \"\"\"\n",
        "        features_list = []\n",
        "\n",
        "        # Define subject categories\n",
        "        all_subjects = ['Mathematics', 'Physics', 'Chemistry', 'Biology', 'English', 'Geography', 'History']\n",
        "        stem_subjects = ['Mathematics', 'Physics', 'Chemistry', 'Biology']\n",
        "        humanities_subjects = ['English', 'Geography', 'History']\n",
        "\n",
        "        # Define interest categories\n",
        "        interest_categories = {\n",
        "            'technology': ['programming', 'computers', 'innovation', 'AI', 'software', 'data', 'machine learning', 'robotics'],\n",
        "            'healthcare': ['medicine', 'nursing', 'biology', 'helping', 'health', 'medical', 'care'],\n",
        "            'business': ['entrepreneurship', 'marketing', 'finance', 'management', 'economics', 'business'],\n",
        "            'creative': ['art', 'design', 'music', 'writing', 'creative', 'media', 'storytelling'],\n",
        "            'social': ['teaching', 'counseling', 'social work', 'psychology', 'education', 'helping people'],\n",
        "            'research': ['research', 'analysis', 'investigation', 'study', 'academic'],\n",
        "            'communication': ['communication', 'public speaking', 'presentation', 'media', 'journalism']\n",
        "        }\n",
        "\n",
        "        for index in students_df.index:\n",
        "            student = students_df.loc[index]\n",
        "\n",
        "            if 'subjects' not in student:\n",
        "                logger.error(f\"Error: 'subjects' not in student data for index {index}. Columns: {student.index.tolist()}\")\n",
        "                continue # Skip this student if 'subjects' is missing\n",
        "\n",
        "            student_subjects = set(student['subjects'].split(', '))\n",
        "            student_interests = set(student['interests'].split(', '))\n",
        "\n",
        "            for _, course in courses_df.iterrows():\n",
        "                course_subjects = set(course['subjects'].split(', '))\n",
        "                course_skills = set(course['skills'].split(', '))\n",
        "\n",
        "                features = {}\n",
        "\n",
        "                # Student ID and Course ID (for reference)\n",
        "                features['student_id'] = student['student_id']\n",
        "                features['course_name'] = course['course_name']\n",
        "\n",
        "                # Basic subject matching features\n",
        "                for subject in all_subjects:\n",
        "                    features[f'student_has_{subject.lower()}'] = 1 if subject in student_subjects else 0\n",
        "                    features[f'course_requires_{subject.lower()}'] = 1 if subject in course_subjects else 0\n",
        "\n",
        "                # Subject overlap features\n",
        "                features['subject_overlap_count'] = len(student_subjects.intersection(course_subjects))\n",
        "                features['subject_overlap_ratio'] = (len(student_subjects.intersection(course_subjects)) /\n",
        "                                                   len(student_subjects.union(course_subjects)) if student_subjects.union(course_subjects) else 0)\n",
        "\n",
        "                # Interest-skill alignment features\n",
        "                features['interest_skill_overlap'] = len(student_interests.intersection(course_skills))\n",
        "                features['interest_skill_ratio'] = (len(student_interests.intersection(course_skills)) /\n",
        "                                                   len(student_interests.union(course_skills)) if student_interests.union(course_skills) else 0)\n",
        "\n",
        "                # Subject category features\n",
        "                student_stem_count = sum(1 for subj in student_subjects if subj in stem_subjects)\n",
        "                student_humanities_count = sum(1 for subj in student_subjects if subj in humanities_subjects)\n",
        "\n",
        "                course_stem_count = sum(1 for subj in course_subjects if subj in stem_subjects)\n",
        "                course_humanities_count = sum(1 for subj in course_subjects if subj in humanities_subjects)\n",
        "\n",
        "                features['student_stem_ratio'] = student_stem_count / len(stem_subjects)\n",
        "                features['student_humanities_ratio'] = student_humanities_count / len(humanities_subjects)\n",
        "                features['course_stem_ratio'] = course_stem_count / len(stem_subjects)\n",
        "                features['course_humanities_ratio'] = course_humanities_count / len(humanities_subjects)\n",
        "\n",
        "                # Alignment between student and course preferences\n",
        "                features['stem_alignment'] = min(features['student_stem_ratio'], features['course_stem_ratio'])\n",
        "                features['humanities_alignment'] = min(features['student_humanities_ratio'], features['course_humanities_ratio'])\n",
        "\n",
        "                # Interest category features\n",
        "                for category, keywords in interest_categories.items():\n",
        "                    student_category_score = sum(1 for interest in student_interests\n",
        "                                               if any(keyword.lower() in interest.lower() for keyword in keywords))\n",
        "                    course_category_score = sum(1 for skill in course_skills\n",
        "                                              if any(keyword.lower() in skill.lower() for keyword in keywords))\n",
        "\n",
        "                    features[f'student_{category}_interest'] = student_category_score\n",
        "                    features[f'course_{category}_relevance'] = course_category_score\n",
        "                    features[f'{category}_alignment'] = min(student_category_score, course_category_score)\n",
        "\n",
        "                # Diversity features\n",
        "                features['student_subject_diversity'] = len(student_subjects)\n",
        "                features['student_interest_diversity'] = len(student_interests)\n",
        "                features['course_subject_breadth'] = len(course_subjects)\n",
        "                features['course_skill_breadth'] = len(course_skills)\n",
        "\n",
        "                # Target variable: compatibility score\n",
        "                subject_score = len(student_subjects.intersection(course_subjects))\n",
        "                interest_score = len(student_interests.intersection(course_skills))\n",
        "                total_possible = len(student_subjects) + len(student_interests)\n",
        "\n",
        "                features['compatibility_score'] = (subject_score + interest_score) / total_possible if total_possible > 0 else 0\n",
        "\n",
        "                features_list.append(features)\n",
        "\n",
        "        return pd.DataFrame(features_list)\n",
        "\n",
        "    def prepare_training_data(self, students_df: pd.DataFrame, courses_df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Prepare training data for XGBoost\n",
        "\n",
        "        Args:\n",
        "            students_df: DataFrame with student information\n",
        "            courses_df: DataFrame with course information\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (features, targets)\n",
        "        \"\"\"\n",
        "        logger.info(\"Extracting advanced features...\")\n",
        "\n",
        "        # Extract features\n",
        "        features_df = self.extract_advanced_features(students_df, courses_df)\n",
        "\n",
        "        # Separate features and target\n",
        "        target_col = 'compatibility_score'\n",
        "        feature_cols = [col for col in features_df.columns\n",
        "                       if col not in ['student_id', 'course_name', target_col]]\n",
        "\n",
        "        X = features_df[feature_cols]\n",
        "        y = features_df[target_col]\n",
        "\n",
        "        # Store feature names\n",
        "        self.feature_names = feature_cols\n",
        "\n",
        "        # Scale features\n",
        "        X_scaled = self.scaler.fit_transform(X)\n",
        "\n",
        "        logger.info(f\"Prepared {X_scaled.shape[0]} training samples with {X_scaled.shape[1]} features\")\n",
        "\n",
        "        return X_scaled, y.values\n",
        "\n",
        "    def train(self, students_df: pd.DataFrame, courses_df: pd.DataFrame,\n",
        "              test_size=0.2, early_stopping_rounds=20):\n",
        "        \"\"\"\n",
        "        Train the XGBoost model\n",
        "\n",
        "        Args:\n",
        "            students_df: DataFrame with student information\n",
        "            courses_df: DataFrame with course information\n",
        "            test_size: Fraction of data for testing\n",
        "            early_stopping_rounds: Early stopping patience\n",
        "        \"\"\"\n",
        "        logger.info(\"Preparing training data...\")\n",
        "\n",
        "        # Prepare training data\n",
        "        X, y = self.prepare_training_data(students_df, courses_df)\n",
        "\n",
        "        # Split data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=test_size, random_state=self.random_state, stratify=None\n",
        "        )\n",
        "\n",
        "        # Initialize XGBoost model\n",
        "        self.model = xgb.XGBRegressor(\n",
        "            n_estimators=self.n_estimators,\n",
        "            max_depth=self.max_depth,\n",
        "            learning_rate=self.learning_rate,\n",
        "            objective=self.objective,\n",
        "            random_state=self.random_state,\n",
        "            reg_alpha=0.1,  # L1 regularization\n",
        "            reg_lambda=0.1,  # L2 regularization\n",
        "            subsample=0.8,   # Subsample ratio\n",
        "            colsample_bytree=0.8,  # Feature sampling\n",
        "            eval_metric='rmse'\n",
        "        )\n",
        "\n",
        "        # Train model without early stopping callbacks to resolve TypeError\n",
        "        logger.info(\"Training XGBoost model...\")\n",
        "\n",
        "        self.model.fit(\n",
        "            X_train, y_train,\n",
        "            eval_set=[(X_train, y_train), (X_test, y_test)],\n",
        "            verbose=False\n",
        "        )\n",
        "\n",
        "        # Evaluate model\n",
        "        train_pred = self.model.predict(X_train)\n",
        "        test_pred = self.model.predict(X_test)\n",
        "\n",
        "        train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))\n",
        "        test_rmse = np.sqrt(mean_squared_error(y_test, test_pred))\n",
        "\n",
        "        logger.info(f\"Training RMSE: {train_rmse:.4f}\")\n",
        "        logger.info(f\"Test RMSE: {test_rmse:.4f}\")\n",
        "\n",
        "        # Feature importance\n",
        "        feature_importance = self.model.feature_importances_\n",
        "        importance_df = pd.DataFrame({\n",
        "            'feature': self.feature_names,\n",
        "            'importance': feature_importance\n",
        "        }).sort_values('importance', ascending=False)\n",
        "\n",
        "        logger.info(\"Top 10 most important features:\")\n",
        "        for _, row in importance_df.head(10).iterrows():\n",
        "            logger.info(f\"  {row['feature']}: {row['importance']:.4f}\")\n",
        "\n",
        "        logger.info(\"Training completed!\")\n",
        "\n",
        "        return {\n",
        "            'train_rmse': train_rmse,\n",
        "            'test_rmse': test_rmse,\n",
        "            'feature_importance': importance_df\n",
        "        }\n",
        "\n",
        "    def predict_for_student(self, student_data: Dict, courses_df: pd.DataFrame, top_k=5) -> List[Tuple[str, float]]:\n",
        "        \"\"\"\n",
        "        Predict career recommendations for a single student\n",
        "\n",
        "        Args:\n",
        "            student_data: Dictionary with 'subjects' and 'interests' keys\n",
        "            courses_df: DataFrame with course information\n",
        "            top_k: Number of top recommendations to return\n",
        "        Returns:\n",
        "            List of (course_name, confidence_score) tuples\n",
        "        \"\"\"\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model not trained yet!\")\n",
        "\n",
        "        # Create a temporary DataFrame for the student\n",
        "        temp_student_df = pd.DataFrame([{\n",
        "            'student_id': 'temp_student',\n",
        "            'subjects': ', '.join(student_data['subjects']),\n",
        "            'interests': ', '.join(student_data['interests'])\n",
        "        }])\n",
        "\n",
        "        # Extract features for all student-course combinations\n",
        "        features_df = self.extract_advanced_features(temp_student_df, courses_df)\n",
        "\n",
        "        # Prepare features for prediction\n",
        "        feature_cols = [col for col in features_df.columns\n",
        "                       if col not in ['student_id', 'course_name', 'compatibility_score']]\n",
        "\n",
        "        X = features_df[feature_cols]\n",
        "        X_scaled = self.scaler.transform(X)\n",
        "\n",
        "        # Make predictions\n",
        "        predictions = self.model.predict(X_scaled)\n",
        "\n",
        "        # Combine with course names\n",
        "        recommendations = []\n",
        "        for i, course_name in enumerate(features_df['course_name']):\n",
        "            recommendations.append((course_name, float(predictions[i])))\n",
        "\n",
        "        # Sort by prediction score and return top K\n",
        "        recommendations.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        return recommendations[:top_k]\n",
        "\n",
        "    def get_feature_importance(self, top_n=20) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Get feature importance from trained model\n",
        "\n",
        "        Args:\n",
        "            top_n: Number of top features to return\n",
        "\n",
        "        Returns:\n",
        "            DataFrame with feature importance\n",
        "        \"\"\"\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model not trained yet!\")\n",
        "\n",
        "        importance_df = pd.DataFrame({\n",
        "            'feature': self.feature_names,\n",
        "            'importance': self.model.feature_importances_\n",
        "        }).sort_values('importance', ascending=False)\n",
        "\n",
        "        return importance_df.head(top_n)\n",
        "\n",
        "    def save_model(self, filepath: str):\n",
        "        \"\"\"Save the trained model and preprocessors\"\"\"\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"No model to save!\")\n",
        "\n",
        "        # Save XGBoost model\n",
        "        self.model.save_model(f\"{filepath}_xgboost.json\")\n",
        "\n",
        "        # Save preprocessors and metadata\n",
        "        with open(f\"{filepath}_preprocessors.pkl\", 'wb') as f:\n",
        "            pickle.dump({\n",
        "                'scaler': self.scaler,\n",
        "                'course_encoder': self.course_encoder,\n",
        "                'feature_names': self.feature_names,\n",
        "                'n_estimators': self.n_estimators,\n",
        "                'max_depth': self.max_depth,\n",
        "                'learning_rate': self.learning_rate,\n",
        "                'objective': self.objective,\n",
        "                'random_state': self.random_state\n",
        "            }, f)\n",
        "\n",
        "        logger.info(f\"Model saved to {filepath}\")\n",
        "\n",
        "    def load_model(self, filepath: str):\n",
        "        \"\"\"Load a trained model and preprocessors\"\"\"\n",
        "        # Load XGBoost model\n",
        "        self.model = xgb.XGBRegressor()\n",
        "        self.model.load_model(f\"{filepath}_xgboost.json\")\n",
        "\n",
        "        # Load preprocessors and metadata\n",
        "        with open(f\"{filepath}_preprocessors.pkl\", 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "            self.scaler = data['scaler']\n",
        "            self.course_encoder = data['course_encoder']\n",
        "            self.feature_names = data['feature_names']\n",
        "            self.n_estimators = data['n_estimators']\n",
        "            self.max_depth = data['max_depth']\n",
        "            self.learning_rate = data['learning_rate']\n",
        "            self.objective = data['objective']\n",
        "            self.random_state = data['random_state']\n",
        "\n",
        "        logger.info(f\"Model loaded from {filepath}\")\n",
        "\n",
        "def main():\n",
        "    students_df = pd.read_csv('./sample_data/student_data.csv', on_bad_lines='skip')\n",
        "    courses_df = pd.read_csv('./sample_data/Courses.csv')\n",
        "\n",
        "    print(\"Columns in students_df:\", students_df.columns)\n",
        "    print(\"Head of students_df:\\n\", students_df.head())\n",
        "    print(\"Columns in courses_df:\", courses_df.columns)\n",
        "\n",
        "    # Initialize recommender\n",
        "    recommender = XGBoostCareerRecommender(\n",
        "        n_estimators=200,\n",
        "        max_depth=8,\n",
        "        learning_rate=0.1,\n",
        "        objective='reg:squarederror'\n",
        "    )\n",
        "\n",
        "    # Train model\n",
        "    results = recommender.train(students_df, courses_df)\n",
        "\n",
        "    # Save model\n",
        "    recommender.save_model('xgboost_career_model')\n",
        "\n",
        "    # Display feature importance\n",
        "    importance_df = recommender.get_feature_importance()\n",
        "    print(\"\\nTop 15 Most Important Features:\")\n",
        "    print(importance_df.head(15))\n",
        "\n",
        "    # Test prediction\n",
        "    test_student = {\n",
        "        'subjects': ['Mathematics', 'Physics'],\n",
        "        'interests': ['Artificial Intelligence', 'Machine Learning']\n",
        "    }\n",
        "\n",
        "    recommendations = recommender.predict_for_student(test_student, courses_df)\n",
        "\n",
        "    print(\"\\nRecommendations for test student:\")\n",
        "    for course, confidence in recommendations:\n",
        "        print(f\"  {course}: {confidence:.3f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgsc1LlztDlt",
        "outputId": "9af2db0e-3f2e-4b42-bfed-82ea76687653"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns in students_df: Index(['student_id', 'subjects', 'interests'], dtype='object')\n",
            "Head of students_df:\n",
            "   student_id                                subjects  \\\n",
            "0       S001  Mathematics, Physics, Computer Studies   \n",
            "1       S002             English, Kiswahili, History   \n",
            "2       S003         Biology, Chemistry, Agriculture   \n",
            "3       S004    Geography, History, Business Studies   \n",
            "4       S005          Art and Design, Music, English   \n",
            "\n",
            "                                    interests  \n",
            "0           Robotics, Artificial Intelligence  \n",
            "1                    Creative Writing, Poetry  \n",
            "2  Environmental Science, Sustainable Farming  \n",
            "3                   Urban Planning, Economics  \n",
            "4                 Graphic Design, Songwriting  \n",
            "Columns in courses_df: Index(['course_id', 'course_name', 'subjects', 'skills'], dtype='object')\n",
            "Successfully accessed 'subjects' for first row: Mathematics, Physics, Computer Studies\n",
            "\n",
            "==================================================\n",
            "COMPREHENSIVE MODEL EVALUATION RESULTS\n",
            "==================================================\n",
            "\n",
            "Regression Metrics:\n",
            "Training RMSE: 0.0005\n",
            "Test RMSE: 0.0006\n",
            "\n",
            "Classification Metrics (Test Set):\n",
            "Accuracy: 0.9864\n",
            "Precision: 1.0000\n",
            "Recall: 0.8377\n",
            "F1-Score: 0.9117\n",
            "\n",
            "Detailed Classification Report:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Not Recommended       0.99      1.00      0.99     57650\n",
            "    Recommended       1.00      0.84      0.91      5261\n",
            "\n",
            "       accuracy                           0.99     62911\n",
            "      macro avg       0.99      0.92      0.95     62911\n",
            "   weighted avg       0.99      0.99      0.99     62911\n",
            "\n",
            "\n",
            "Top 15 Most Important Features:\n",
            "                       feature  importance\n",
            "14       subject_overlap_count    0.901424\n",
            "15       subject_overlap_ratio    0.075985\n",
            "45   student_subject_diversity    0.008156\n",
            "22              stem_alignment    0.004043\n",
            "46  student_interest_diversity    0.002899\n",
            "16      interest_skill_overlap    0.001582\n",
            "17        interest_skill_ratio    0.000943\n",
            "18          student_stem_ratio    0.000761\n",
            "3      course_requires_physics    0.000586\n",
            "47      course_subject_breadth    0.000512\n",
            "9      course_requires_english    0.000499\n",
            "2          student_has_physics    0.000445\n",
            "6          student_has_biology    0.000380\n",
            "4        student_has_chemistry    0.000285\n",
            "20           course_stem_ratio    0.000157\n",
            "\n",
            "Recommendations for test student:\n",
            "  Bachelor of Science (Geospatial Information Science With IT): 0.437\n",
            "  Bachelor of Technology (Geoinformation Technology): 0.437\n",
            "  Bachelor of Science (Computer Science): 0.437\n",
            "  Bachelor of Science (Mathematics & Computer Science): 0.437\n",
            "  Bachelor of Science in Computer Science: 0.437\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, mean_squared_error, classification_report\n",
        "import pickle\n",
        "import logging\n",
        "from typing import List, Dict, Tuple\n",
        "import itertools\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class XGBoostCareerRecommender:\n",
        "    def __init__(self, n_estimators=100, max_depth=6, learning_rate=0.1,\n",
        "                 objective='reg:squarederror', random_state=42, classification_threshold=0.5):\n",
        "        \"\"\"\n",
        "        Initialize the XGBoost Career Recommender\n",
        "\n",
        "        Args:\n",
        "            n_estimators: Number of boosting rounds\n",
        "            max_depth: Maximum depth of trees\n",
        "            learning_rate: Learning rate\n",
        "            objective: XGBoost objective function\n",
        "            random_state: Random seed for reproducibility\n",
        "            classification_threshold: Threshold for converting regression to classification\n",
        "        \"\"\"\n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_depth = max_depth\n",
        "        self.learning_rate = learning_rate\n",
        "        self.objective = objective\n",
        "        self.random_state = random_state\n",
        "        self.classification_threshold = classification_threshold\n",
        "\n",
        "        self.model = None\n",
        "        self.scaler = StandardScaler()\n",
        "        self.course_encoder = LabelEncoder()\n",
        "        self.feature_names = []\n",
        "\n",
        "    # ...existing code... (extract_advanced_features and prepare_training_data methods remain the same)\n",
        "\n",
        "    def extract_advanced_features(self, students_df: pd.DataFrame, courses_df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Extract comprehensive features for XGBoost training\n",
        "\n",
        "        Args:\n",
        "            students_df: DataFrame with student information\n",
        "            courses_df: DataFrame with course information\n",
        "\n",
        "        Returns:\n",
        "            DataFrame with engineered features\n",
        "        \"\"\"\n",
        "        features_list = []\n",
        "\n",
        "        # Define subject categories\n",
        "        all_subjects = ['Mathematics', 'Physics', 'Chemistry', 'Biology', 'English', 'Geography', 'History']\n",
        "        stem_subjects = ['Mathematics', 'Physics', 'Chemistry', 'Biology']\n",
        "        humanities_subjects = ['English', 'Geography', 'History']\n",
        "\n",
        "        # Define interest categories\n",
        "        interest_categories = {\n",
        "            'technology': ['programming', 'computers', 'innovation', 'AI', 'software', 'data', 'machine learning', 'robotics'],\n",
        "            'healthcare': ['medicine', 'nursing', 'biology', 'helping', 'health', 'medical', 'care'],\n",
        "            'business': ['entrepreneurship', 'marketing', 'finance', 'management', 'economics', 'business'],\n",
        "            'creative': ['art', 'design', 'music', 'writing', 'creative', 'media', 'storytelling'],\n",
        "            'social': ['teaching', 'counseling', 'social work', 'psychology', 'education', 'helping people'],\n",
        "            'research': ['research', 'analysis', 'investigation', 'study', 'academic'],\n",
        "            'communication': ['communication', 'public speaking', 'presentation', 'media', 'journalism']\n",
        "        }\n",
        "\n",
        "        for index in students_df.index:\n",
        "            student = students_df.loc[index]\n",
        "\n",
        "            if 'subjects' not in student:\n",
        "                logger.error(f\"Error: 'subjects' not in student data for index {index}. Columns: {student.index.tolist()}\")\n",
        "                continue # Skip this student if 'subjects' is missing\n",
        "\n",
        "            student_subjects = set(student['subjects'].split(', '))\n",
        "            student_interests = set(student['interests'].split(', '))\n",
        "\n",
        "            for _, course in courses_df.iterrows():\n",
        "                course_subjects = set(course['subjects'].split(', '))\n",
        "                course_skills = set(course['skills'].split(', '))\n",
        "\n",
        "                features = {}\n",
        "\n",
        "                # Student ID and Course ID (for reference)\n",
        "                features['student_id'] = student['student_id']\n",
        "                features['course_name'] = course['course_name']\n",
        "\n",
        "                # Basic subject matching features\n",
        "                for subject in all_subjects:\n",
        "                    features[f'student_has_{subject.lower()}'] = 1 if subject in student_subjects else 0\n",
        "                    features[f'course_requires_{subject.lower()}'] = 1 if subject in course_subjects else 0\n",
        "\n",
        "                # Subject overlap features\n",
        "                features['subject_overlap_count'] = len(student_subjects.intersection(course_subjects))\n",
        "                features['subject_overlap_ratio'] = (len(student_subjects.intersection(course_subjects)) /\n",
        "                                                   len(student_subjects.union(course_subjects)) if student_subjects.union(course_subjects) else 0)\n",
        "\n",
        "                # Interest-skill alignment features\n",
        "                features['interest_skill_overlap'] = len(student_interests.intersection(course_skills))\n",
        "                features['interest_skill_ratio'] = (len(student_interests.intersection(course_skills)) /\n",
        "                                                   len(student_interests.union(course_skills)) if student_interests.union(course_skills) else 0)\n",
        "\n",
        "                # Subject category features\n",
        "                student_stem_count = sum(1 for subj in student_subjects if subj in stem_subjects)\n",
        "                student_humanities_count = sum(1 for subj in student_subjects if subj in humanities_subjects)\n",
        "\n",
        "                course_stem_count = sum(1 for subj in course_subjects if subj in stem_subjects)\n",
        "                course_humanities_count = sum(1 for subj in course_subjects if subj in humanities_subjects)\n",
        "\n",
        "                features['student_stem_ratio'] = student_stem_count / len(stem_subjects)\n",
        "                features['student_humanities_ratio'] = student_humanities_count / len(humanities_subjects)\n",
        "                features['course_stem_ratio'] = course_stem_count / len(stem_subjects)\n",
        "                features['course_humanities_ratio'] = course_humanities_count / len(humanities_subjects)\n",
        "\n",
        "                # Alignment between student and course preferences\n",
        "                features['stem_alignment'] = min(features['student_stem_ratio'], features['course_stem_ratio'])\n",
        "                features['humanities_alignment'] = min(features['student_humanities_ratio'], features['course_humanities_ratio'])\n",
        "\n",
        "                # Interest category features\n",
        "                for category, keywords in interest_categories.items():\n",
        "                    student_category_score = sum(1 for interest in student_interests\n",
        "                                               if any(keyword.lower() in interest.lower() for keyword in keywords))\n",
        "                    course_category_score = sum(1 for skill in course_skills\n",
        "                                              if any(keyword.lower() in skill.lower() for keyword in keywords))\n",
        "\n",
        "                    features[f'student_{category}_interest'] = student_category_score\n",
        "                    features[f'course_{category}_relevance'] = course_category_score\n",
        "                    features[f'{category}_alignment'] = min(student_category_score, course_category_score)\n",
        "\n",
        "                # Diversity features\n",
        "                features['student_subject_diversity'] = len(student_subjects)\n",
        "                features['student_interest_diversity'] = len(student_interests)\n",
        "                features['course_subject_breadth'] = len(course_subjects)\n",
        "                features['course_skill_breadth'] = len(course_skills)\n",
        "\n",
        "                # Target variable: compatibility score\n",
        "                subject_score = len(student_subjects.intersection(course_subjects))\n",
        "                interest_score = len(student_interests.intersection(course_skills))\n",
        "                total_possible = len(student_subjects) + len(student_interests)\n",
        "\n",
        "                features['compatibility_score'] = (subject_score + interest_score) / total_possible if total_possible > 0 else 0\n",
        "\n",
        "                features_list.append(features)\n",
        "\n",
        "        return pd.DataFrame(features_list)\n",
        "\n",
        "    def prepare_training_data(self, students_df: pd.DataFrame, courses_df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Prepare training data for XGBoost\n",
        "\n",
        "        Args:\n",
        "            students_df: DataFrame with student information\n",
        "            courses_df: DataFrame with course information\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (features, targets)\n",
        "        \"\"\"\n",
        "        logger.info(\"Extracting advanced features...\")\n",
        "\n",
        "        # Extract features\n",
        "        features_df = self.extract_advanced_features(students_df, courses_df)\n",
        "\n",
        "        # Separate features and target\n",
        "        target_col = 'compatibility_score'\n",
        "        feature_cols = [col for col in features_df.columns\n",
        "                       if col not in ['student_id', 'course_name', target_col]]\n",
        "\n",
        "        X = features_df[feature_cols]\n",
        "        y = features_df[target_col]\n",
        "\n",
        "        # Store feature names\n",
        "        self.feature_names = feature_cols\n",
        "\n",
        "        # Scale features\n",
        "        X_scaled = self.scaler.fit_transform(X)\n",
        "\n",
        "        logger.info(f\"Prepared {X_scaled.shape[0]} training samples with {X_scaled.shape[1]} features\")\n",
        "\n",
        "        return X_scaled, y.values\n",
        "\n",
        "    def evaluate_classification_metrics(self, y_true, y_pred):\n",
        "        \"\"\"\n",
        "        Calculate classification metrics by converting regression predictions to binary classification\n",
        "\n",
        "        Args:\n",
        "            y_true: True compatibility scores\n",
        "            y_pred: Predicted compatibility scores\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with classification metrics\n",
        "        \"\"\"\n",
        "        # Convert regression to binary classification\n",
        "        y_true_binary = (y_true >= self.classification_threshold).astype(int)\n",
        "        y_pred_binary = (y_pred >= self.classification_threshold).astype(int)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = accuracy_score(y_true_binary, y_pred_binary)\n",
        "\n",
        "        # Calculate precision, recall, f1-score\n",
        "        precision, recall, f1, support = precision_recall_fscore_support(\n",
        "            y_true_binary, y_pred_binary, average='binary'\n",
        "        )\n",
        "\n",
        "        # Calculate macro and weighted averages\n",
        "        precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
        "            y_true_binary, y_pred_binary, average='macro'\n",
        "        )\n",
        "\n",
        "        precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
        "            y_true_binary, y_pred_binary, average='weighted'\n",
        "        )\n",
        "\n",
        "        # Generate classification report\n",
        "        class_report = classification_report(\n",
        "            y_true_binary, y_pred_binary,\n",
        "            target_names=['Not Recommended', 'Recommended'],\n",
        "            output_dict=True\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'precision_binary': precision,\n",
        "            'recall_binary': recall,\n",
        "            'f1_binary': f1,\n",
        "            'precision_macro': precision_macro,\n",
        "            'recall_macro': recall_macro,\n",
        "            'f1_macro': f1_macro,\n",
        "            'precision_weighted': precision_weighted,\n",
        "            'recall_weighted': recall_weighted,\n",
        "            'f1_weighted': f1_weighted,\n",
        "            'classification_report': class_report,\n",
        "            'threshold_used': self.classification_threshold\n",
        "        }\n",
        "\n",
        "    def train(self, students_df: pd.DataFrame, courses_df: pd.DataFrame,\n",
        "              test_size=0.2, early_stopping_rounds=20):\n",
        "        \"\"\"\n",
        "        Train the XGBoost model with comprehensive evaluation\n",
        "\n",
        "        Args:\n",
        "            students_df: DataFrame with student information\n",
        "            courses_df: DataFrame with course information\n",
        "            test_size: Fraction of data for testing\n",
        "            early_stopping_rounds: Early stopping patience\n",
        "        \"\"\"\n",
        "        logger.info(\"Preparing training data...\")\n",
        "\n",
        "        # Prepare training data\n",
        "        X, y = self.prepare_training_data(students_df, courses_df)\n",
        "\n",
        "        # Split data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=test_size, random_state=self.random_state, stratify=None\n",
        "        )\n",
        "\n",
        "        # Initialize XGBoost model\n",
        "        self.model = xgb.XGBRegressor(\n",
        "            n_estimators=self.n_estimators,\n",
        "            max_depth=self.max_depth,\n",
        "            learning_rate=self.learning_rate,\n",
        "            objective=self.objective,\n",
        "            random_state=self.random_state,\n",
        "            reg_alpha=0.1,  # L1 regularization\n",
        "            reg_lambda=0.1,  # L2 regularization\n",
        "            subsample=0.8,   # Subsample ratio\n",
        "            colsample_bytree=0.8,  # Feature sampling\n",
        "            eval_metric='rmse'\n",
        "        )\n",
        "\n",
        "        # Train model\n",
        "        logger.info(\"Training XGBoost model...\")\n",
        "\n",
        "        self.model.fit(\n",
        "            X_train, y_train,\n",
        "            eval_set=[(X_train, y_train), (X_test, y_test)],\n",
        "            verbose=False\n",
        "        )\n",
        "\n",
        "        # Evaluate model - Regression metrics\n",
        "        train_pred = self.model.predict(X_train)\n",
        "        test_pred = self.model.predict(X_test)\n",
        "\n",
        "        train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))\n",
        "        test_rmse = np.sqrt(mean_squared_error(y_test, test_pred))\n",
        "\n",
        "        logger.info(f\"Training RMSE: {train_rmse:.4f}\")\n",
        "        logger.info(f\"Test RMSE: {test_rmse:.4f}\")\n",
        "\n",
        "        # Evaluate model - Classification metrics\n",
        "        train_classification_metrics = self.evaluate_classification_metrics(y_train, train_pred)\n",
        "        test_classification_metrics = self.evaluate_classification_metrics(y_test, test_pred)\n",
        "\n",
        "        logger.info(\"\\n=== TRAINING SET CLASSIFICATION METRICS ===\")\n",
        "        logger.info(f\"Accuracy: {train_classification_metrics['accuracy']:.4f}\")\n",
        "        logger.info(f\"Precision (binary): {train_classification_metrics['precision_binary']:.4f}\")\n",
        "        logger.info(f\"Recall (binary): {train_classification_metrics['recall_binary']:.4f}\")\n",
        "        logger.info(f\"F1-Score (binary): {train_classification_metrics['f1_binary']:.4f}\")\n",
        "        logger.info(f\"F1-Score (macro): {train_classification_metrics['f1_macro']:.4f}\")\n",
        "        logger.info(f\"F1-Score (weighted): {train_classification_metrics['f1_weighted']:.4f}\")\n",
        "\n",
        "        logger.info(\"\\n=== TEST SET CLASSIFICATION METRICS ===\")\n",
        "        logger.info(f\"Accuracy: {test_classification_metrics['accuracy']:.4f}\")\n",
        "        logger.info(f\"Precision (binary): {test_classification_metrics['precision_binary']:.4f}\")\n",
        "        logger.info(f\"Recall (binary): {test_classification_metrics['recall_binary']:.4f}\")\n",
        "        logger.info(f\"F1-Score (binary): {test_classification_metrics['f1_binary']:.4f}\")\n",
        "        logger.info(f\"F1-Score (macro): {test_classification_metrics['f1_macro']:.4f}\")\n",
        "        logger.info(f\"F1-Score (weighted): {test_classification_metrics['f1_weighted']:.4f}\")\n",
        "\n",
        "        # Feature importance\n",
        "        feature_importance = self.model.feature_importances_\n",
        "        importance_df = pd.DataFrame({\n",
        "            'feature': self.feature_names,\n",
        "            'importance': feature_importance\n",
        "        }).sort_values('importance', ascending=False)\n",
        "\n",
        "        logger.info(\"\\nTop 10 most important features:\")\n",
        "        for _, row in importance_df.head(10).iterrows():\n",
        "            logger.info(f\"  {row['feature']}: {row['importance']:.4f}\")\n",
        "\n",
        "        logger.info(\"Training completed!\")\n",
        "\n",
        "        return {\n",
        "            'train_rmse': train_rmse,\n",
        "            'test_rmse': test_rmse,\n",
        "            'train_classification_metrics': train_classification_metrics,\n",
        "            'test_classification_metrics': test_classification_metrics,\n",
        "            'feature_importance': importance_df\n",
        "        }\n",
        "\n",
        "    def detailed_classification_report(self, y_true, y_pred):\n",
        "        \"\"\"\n",
        "        Generate a detailed classification report\n",
        "\n",
        "        Args:\n",
        "            y_true: True compatibility scores\n",
        "            y_pred: Predicted compatibility scores\n",
        "\n",
        "        Returns:\n",
        "            Formatted classification report string\n",
        "        \"\"\"\n",
        "        y_true_binary = (y_true >= self.classification_threshold).astype(int)\n",
        "        y_pred_binary = (y_pred >= self.classification_threshold).astype(int)\n",
        "\n",
        "        report = classification_report(\n",
        "            y_true_binary, y_pred_binary,\n",
        "            target_names=['Not Recommended', 'Recommended']\n",
        "        )\n",
        "\n",
        "        return report\n",
        "\n",
        "    def predict_for_student(self, student_data: Dict, courses_df: pd.DataFrame, top_k=5) -> List[Tuple[str, float]]:\n",
        "        \"\"\"\n",
        "        Predict career recommendations for a single student\n",
        "\n",
        "        Args:\n",
        "            student_data: Dictionary with 'subjects' and 'interests' keys\n",
        "            courses_df: DataFrame with course information\n",
        "            top_k: Number of top recommendations to return\n",
        "        Returns:\n",
        "            List of (course_name, confidence_score) tuples\n",
        "        \"\"\"\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model not trained yet!\")\n",
        "\n",
        "        # Create a temporary DataFrame for the student\n",
        "        temp_student_df = pd.DataFrame([{\n",
        "            'student_id': 'temp_student',\n",
        "            'subjects': ', '.join(student_data['subjects']),\n",
        "            'interests': ', '.join(student_data['interests'])\n",
        "        }])\n",
        "\n",
        "        # Extract features for all student-course combinations\n",
        "        features_df = self.extract_advanced_features(temp_student_df, courses_df)\n",
        "\n",
        "        # Prepare features for prediction\n",
        "        feature_cols = [col for col in features_df.columns\n",
        "                       if col not in ['student_id', 'course_name', 'compatibility_score']]\n",
        "\n",
        "        X = features_df[feature_cols]\n",
        "        X_scaled = self.scaler.transform(X)\n",
        "\n",
        "        # Make predictions\n",
        "        predictions = self.model.predict(X_scaled)\n",
        "\n",
        "        # Combine with course names\n",
        "        recommendations = []\n",
        "        for i, course_name in enumerate(features_df['course_name']):\n",
        "            recommendations.append((course_name, float(predictions[i])))\n",
        "\n",
        "        # Sort by prediction score and return top K\n",
        "        recommendations.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        return recommendations[:top_k]\n",
        "\n",
        "    def get_feature_importance(self, top_n=20) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Get feature importance from trained model\n",
        "\n",
        "        Args:\n",
        "            top_n: Number of top features to return\n",
        "\n",
        "        Returns:\n",
        "            DataFrame with feature importance\n",
        "        \"\"\"\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model not trained yet!\")\n",
        "\n",
        "        importance_df = pd.DataFrame({\n",
        "            'feature': self.feature_names,\n",
        "            'importance': self.model.feature_importances_\n",
        "        }).sort_values('importance', ascending=False)\n",
        "\n",
        "        return importance_df.head(top_n)\n",
        "\n",
        "    def save_model(self, filepath: str):\n",
        "        \"\"\"Save the trained model and preprocessors\"\"\"\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"No model to save!\")\n",
        "\n",
        "        # Save XGBoost model\n",
        "        self.model.save_model(f\"{filepath}_xgboost.json\")\n",
        "\n",
        "        # Save preprocessors and metadata\n",
        "        with open(f\"{filepath}_preprocessors.pkl\", 'wb') as f:\n",
        "            pickle.dump({\n",
        "                'scaler': self.scaler,\n",
        "                'course_encoder': self.course_encoder,\n",
        "                'feature_names': self.feature_names,\n",
        "                'n_estimators': self.n_estimators,\n",
        "                'max_depth': self.max_depth,\n",
        "                'learning_rate': self.learning_rate,\n",
        "                'objective': self.objective,\n",
        "                'random_state': self.random_state,\n",
        "                'classification_threshold': self.classification_threshold\n",
        "            }, f)\n",
        "\n",
        "        logger.info(f\"Model saved to {filepath}\")\n",
        "\n",
        "    def load_model(self, filepath: str):\n",
        "        \"\"\"Load a trained model and preprocessors\"\"\"\n",
        "        # Load XGBoost model\n",
        "        self.model = xgb.XGBRegressor()\n",
        "        self.model.load_model(f\"{filepath}_xgboost.json\")\n",
        "\n",
        "        # Load preprocessors and metadata\n",
        "        with open(f\"{filepath}_preprocessors.pkl\", 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "            self.scaler = data['scaler']\n",
        "            self.course_encoder = data['course_encoder']\n",
        "            self.feature_names = data['feature_names']\n",
        "            self.n_estimators = data['n_estimators']\n",
        "            self.max_depth = data['max_depth']\n",
        "            self.learning_rate = data['learning_rate']\n",
        "            self.objective = data['objective']\n",
        "            self.random_state = data['random_state']\n",
        "            self.classification_threshold = data.get('classification_threshold', 0.5)\n",
        "\n",
        "        logger.info(f\"Model loaded from {filepath}\")\n",
        "\n",
        "# Example usage and training script\n",
        "def main():\n",
        "    # Load data\n",
        "    students_df = pd.read_csv('./sample_data/student_data.csv', on_bad_lines='skip')\n",
        "    courses_df = pd.read_csv('./sample_data/Courses.csv')\n",
        "\n",
        "    print(\"Columns in students_df:\", students_df.columns)\n",
        "    print(\"Head of students_df:\\n\", students_df.head())\n",
        "    print(\"Columns in courses_df:\", courses_df.columns)\n",
        "\n",
        "    # Debugging: Access 'subjects' column for the first row\n",
        "    if not students_df.empty:\n",
        "        try:\n",
        "            first_subject = students_df.loc[0, 'subjects']\n",
        "            print(f\"Successfully accessed 'subjects' for first row: {first_subject}\")\n",
        "        except KeyError as e:\n",
        "            print(f\"KeyError when accessing 'subjects' for first row: {e}\")\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred when accessing 'subjects' for first row: {e}\")\n",
        "\n",
        "    # Initialize recommender with classification threshold\n",
        "    recommender = XGBoostCareerRecommender(\n",
        "        n_estimators=200,\n",
        "        max_depth=8,\n",
        "        learning_rate=0.1,\n",
        "        objective='reg:squarederror',\n",
        "        classification_threshold=0.5  # Adjust this threshold as needed\n",
        "    )\n",
        "\n",
        "    # Train model\n",
        "    results = recommender.train(students_df, courses_df)\n",
        "\n",
        "    # Save model\n",
        "    recommender.save_model('xgboost_career_model')\n",
        "\n",
        "    # Display detailed results\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"COMPREHENSIVE MODEL EVALUATION RESULTS\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    print(\"\\nRegression Metrics:\")\n",
        "    print(f\"Training RMSE: {results['train_rmse']:.4f}\")\n",
        "    print(f\"Test RMSE: {results['test_rmse']:.4f}\")\n",
        "\n",
        "    print(\"\\nClassification Metrics (Test Set):\")\n",
        "    test_metrics = results['test_classification_metrics']\n",
        "    print(f\"Accuracy: {test_metrics['accuracy']:.4f}\")\n",
        "    print(f\"Precision: {test_metrics['precision_binary']:.4f}\")\n",
        "    print(f\"Recall: {test_metrics['recall_binary']:.4f}\")\n",
        "    print(f\"F1-Score: {test_metrics['f1_binary']:.4f}\")\n",
        "\n",
        "    print(\"\\nDetailed Classification Report:\")\n",
        "    # Create dummy data for demonstration of the report function\n",
        "    X, y = recommender.prepare_training_data(students_df, courses_df)\n",
        "    _, X_test, _, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    test_pred = recommender.model.predict(X_test)\n",
        "    print(recommender.detailed_classification_report(y_test, test_pred))\n",
        "\n",
        "    # Display feature importance\n",
        "    importance_df = recommender.get_feature_importance()\n",
        "    print(\"\\nTop 15 Most Important Features:\")\n",
        "    print(importance_df.head(15))\n",
        "\n",
        "    # Test prediction\n",
        "    test_student = {\n",
        "        'subjects': ['Mathematics', 'Physics'],\n",
        "        'interests': ['Artificial Intelligence', 'Machine Learning']\n",
        "    }\n",
        "\n",
        "    recommendations = recommender.predict_for_student(test_student, courses_df)\n",
        "\n",
        "    print(\"\\nRecommendations for test student:\")\n",
        "    for course, confidence in recommendations:\n",
        "        print(f\"  {course}: {confidence:.3f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
