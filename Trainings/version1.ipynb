{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7Be7qnkPyig9",
        "outputId": "a0a48eb8-9cf5-4c16-e28c-910d4c68e2d2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ student_id          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ course_id           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">70,144</span> │ student_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,472</span> │ course_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ features            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">271</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │                   │            │ features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">69,632</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │                   │            │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ rating (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ student_id          │ (\u001b[38;5;45mNone\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ course_id           │ (\u001b[38;5;45mNone\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m70,144\u001b[0m │ student_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m73,472\u001b[0m │ course_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ features            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m271\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │                   │            │ features[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m69,632\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m512\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m256\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply (\u001b[38;5;33mMultiply\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │                   │            │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ rating (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">260,482</span> (1017.51 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m260,482\u001b[0m (1017.51 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">259,586</span> (1014.01 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m259,586\u001b[0m (1014.01 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 13ms/step - accuracy: 0.4392 - loss: 0.4900 - mae: 0.1434 - val_accuracy: 0.0550 - val_loss: 0.6637 - val_mae: 0.1499 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.4488 - loss: 0.3824 - mae: 0.0866 - val_accuracy: 0.0550 - val_loss: 0.6696 - val_mae: 0.1494 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 13ms/step - accuracy: 0.4486 - loss: 0.3709 - mae: 0.0678 - val_accuracy: 0.0550 - val_loss: 0.6601 - val_mae: 0.1368 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.4471 - loss: 0.3643 - mae: 0.0559 - val_accuracy: 0.0550 - val_loss: 0.6481 - val_mae: 0.1118 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.4487 - loss: 0.3584 - mae: 0.0466 - val_accuracy: 0.0548 - val_loss: 0.6344 - val_mae: 0.0906 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 13ms/step - accuracy: 0.4492 - loss: 0.3543 - mae: 0.0424 - val_accuracy: 0.0549 - val_loss: 0.6327 - val_mae: 0.0912 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.4486 - loss: 0.3519 - mae: 0.0387 - val_accuracy: 0.0550 - val_loss: 0.6265 - val_mae: 0.0829 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 14ms/step - accuracy: 0.4505 - loss: 0.3501 - mae: 0.0359 - val_accuracy: 0.0549 - val_loss: 0.6247 - val_mae: 0.0787 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 14ms/step - accuracy: 0.4478 - loss: 0.3505 - mae: 0.0338 - val_accuracy: 0.0548 - val_loss: 0.6250 - val_mae: 0.0785 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 13ms/step - accuracy: 0.4474 - loss: 0.3498 - mae: 0.0324 - val_accuracy: 0.0550 - val_loss: 0.6287 - val_mae: 0.0809 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 13ms/step - accuracy: 0.4461 - loss: 0.3500 - mae: 0.0313 - val_accuracy: 0.0550 - val_loss: 0.6277 - val_mae: 0.0813 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.4494 - loss: 0.3482 - mae: 0.0300 - val_accuracy: 0.0550 - val_loss: 0.6304 - val_mae: 0.0825 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 13ms/step - accuracy: 0.4473 - loss: 0.3484 - mae: 0.0292 - val_accuracy: 0.0550 - val_loss: 0.6268 - val_mae: 0.0808 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.4463 - loss: 0.3486 - mae: 0.0287 - val_accuracy: 0.0550 - val_loss: 0.6268 - val_mae: 0.0775 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m1963/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4466 - loss: 0.3478 - mae: 0.0279\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 13ms/step - accuracy: 0.4466 - loss: 0.3478 - mae: 0.0279 - val_accuracy: 0.0550 - val_loss: 0.6265 - val_mae: 0.0763 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.4487 - loss: 0.3343 - mae: 0.0218 - val_accuracy: 0.0550 - val_loss: 0.6179 - val_mae: 0.0742 - learning_rate: 5.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 13ms/step - accuracy: 0.4478 - loss: 0.3333 - mae: 0.0204 - val_accuracy: 0.0550 - val_loss: 0.6156 - val_mae: 0.0735 - learning_rate: 5.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 13ms/step - accuracy: 0.4466 - loss: 0.3326 - mae: 0.0195 - val_accuracy: 0.0550 - val_loss: 0.6153 - val_mae: 0.0739 - learning_rate: 5.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 12ms/step - accuracy: 0.4472 - loss: 0.3323 - mae: 0.0189 - val_accuracy: 0.0550 - val_loss: 0.6156 - val_mae: 0.0772 - learning_rate: 5.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 13ms/step - accuracy: 0.4491 - loss: 0.3317 - mae: 0.0186 - val_accuracy: 0.0548 - val_loss: 0.6183 - val_mae: 0.0842 - learning_rate: 5.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.4480 - loss: 0.3315 - mae: 0.0181 - val_accuracy: 0.0550 - val_loss: 0.6155 - val_mae: 0.0744 - learning_rate: 5.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 13ms/step - accuracy: 0.4467 - loss: 0.3318 - mae: 0.0174 - val_accuracy: 0.0550 - val_loss: 0.6152 - val_mae: 0.0761 - learning_rate: 5.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 12ms/step - accuracy: 0.4490 - loss: 0.3306 - mae: 0.0174 - val_accuracy: 0.0550 - val_loss: 0.6177 - val_mae: 0.0778 - learning_rate: 5.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.4472 - loss: 0.3325 - mae: 0.0173 - val_accuracy: 0.0550 - val_loss: 0.6153 - val_mae: 0.0754 - learning_rate: 5.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 13ms/step - accuracy: 0.4481 - loss: 0.3306 - mae: 0.0164 - val_accuracy: 0.0550 - val_loss: 0.6136 - val_mae: 0.0743 - learning_rate: 5.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 13ms/step - accuracy: 0.4462 - loss: 0.3315 - mae: 0.0160 - val_accuracy: 0.0550 - val_loss: 0.6174 - val_mae: 0.0808 - learning_rate: 5.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.4474 - loss: 0.3313 - mae: 0.0162 - val_accuracy: 0.0550 - val_loss: 0.6144 - val_mae: 0.0787 - learning_rate: 5.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 12ms/step - accuracy: 0.4478 - loss: 0.3302 - mae: 0.0158 - val_accuracy: 0.0550 - val_loss: 0.6168 - val_mae: 0.0803 - learning_rate: 5.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 13ms/step - accuracy: 0.4471 - loss: 0.3314 - mae: 0.0162 - val_accuracy: 0.0550 - val_loss: 0.6163 - val_mae: 0.0832 - learning_rate: 5.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.4509 - loss: 0.3287 - mae: 0.0157 - val_accuracy: 0.0550 - val_loss: 0.6172 - val_mae: 0.0829 - learning_rate: 5.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.4478 - loss: 0.3301 - mae: 0.0153 - val_accuracy: 0.0550 - val_loss: 0.6198 - val_mae: 0.0866 - learning_rate: 5.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4479 - loss: 0.3305 - mae: 0.0152\n",
            "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 12ms/step - accuracy: 0.4479 - loss: 0.3305 - mae: 0.0152 - val_accuracy: 0.0548 - val_loss: 0.6164 - val_mae: 0.0844 - learning_rate: 5.0000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 13ms/step - accuracy: 0.4479 - loss: 0.3221 - mae: 0.0116 - val_accuracy: 0.0550 - val_loss: 0.6136 - val_mae: 0.0846 - learning_rate: 2.5000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 13ms/step - accuracy: 0.4476 - loss: 0.3215 - mae: 0.0119 - val_accuracy: 0.0550 - val_loss: 0.6123 - val_mae: 0.0883 - learning_rate: 2.5000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.4479 - loss: 0.3202 - mae: 0.0110 - val_accuracy: 0.0550 - val_loss: 0.6137 - val_mae: 0.0845 - learning_rate: 2.5000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.4495 - loss: 0.3199 - mae: 0.0114 - val_accuracy: 0.0550 - val_loss: 0.6138 - val_mae: 0.0861 - learning_rate: 2.5000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 12ms/step - accuracy: 0.4479 - loss: 0.3201 - mae: 0.0108 - val_accuracy: 0.0550 - val_loss: 0.6106 - val_mae: 0.0843 - learning_rate: 2.5000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 13ms/step - accuracy: 0.4478 - loss: 0.3202 - mae: 0.0109 - val_accuracy: 0.0550 - val_loss: 0.6143 - val_mae: 0.0861 - learning_rate: 2.5000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.4465 - loss: 0.3206 - mae: 0.0106 - val_accuracy: 0.0550 - val_loss: 0.6130 - val_mae: 0.0900 - learning_rate: 2.5000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 13ms/step - accuracy: 0.4483 - loss: 0.3204 - mae: 0.0108 - val_accuracy: 0.0550 - val_loss: 0.6127 - val_mae: 0.0889 - learning_rate: 2.5000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.4480 - loss: 0.3202 - mae: 0.0110 - val_accuracy: 0.0550 - val_loss: 0.6137 - val_mae: 0.0879 - learning_rate: 2.5000e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 12ms/step - accuracy: 0.4485 - loss: 0.3197 - mae: 0.0106 - val_accuracy: 0.0550 - val_loss: 0.6154 - val_mae: 0.0893 - learning_rate: 2.5000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 12ms/step - accuracy: 0.4498 - loss: 0.3189 - mae: 0.0103 - val_accuracy: 0.0550 - val_loss: 0.6121 - val_mae: 0.0886 - learning_rate: 2.5000e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m1963/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4479 - loss: 0.3198 - mae: 0.0103\n",
            "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 13ms/step - accuracy: 0.4479 - loss: 0.3198 - mae: 0.0103 - val_accuracy: 0.0550 - val_loss: 0.6122 - val_mae: 0.0877 - learning_rate: 2.5000e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 13ms/step - accuracy: 0.4467 - loss: 0.3172 - mae: 0.0087 - val_accuracy: 0.0550 - val_loss: 0.6104 - val_mae: 0.0860 - learning_rate: 1.2500e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 12ms/step - accuracy: 0.4478 - loss: 0.3150 - mae: 0.0083 - val_accuracy: 0.0550 - val_loss: 0.6108 - val_mae: 0.0884 - learning_rate: 1.2500e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 12ms/step - accuracy: 0.4460 - loss: 0.3161 - mae: 0.0081 - val_accuracy: 0.0550 - val_loss: 0.6095 - val_mae: 0.0864 - learning_rate: 1.2500e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 13ms/step - accuracy: 0.4483 - loss: 0.3146 - mae: 0.0083 - val_accuracy: 0.0550 - val_loss: 0.6114 - val_mae: 0.0887 - learning_rate: 1.2500e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 13ms/step - accuracy: 0.4481 - loss: 0.3145 - mae: 0.0080 - val_accuracy: 0.0550 - val_loss: 0.6105 - val_mae: 0.0877 - learning_rate: 1.2500e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m1966/1966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 13ms/step - accuracy: 0.4477 - loss: 0.3146 - mae: 0.0079 - val_accuracy: 0.0550 - val_loss: 0.6098 - val_mae: 0.0853 - learning_rate: 1.2500e-04\n",
            "Restoring model weights from the end of the best epoch: 47.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations for test student:\n",
            "  Bachelor of Education (French With IT): 0.597\n",
            "  Bachelor of Education Arts: 0.594\n",
            "  Bachelor of Science (Animal Health Production & Processing): 0.591\n",
            "  Bachelor of Science (Applied Aquatic Science): 0.591\n",
            "  Bachelor of Science (Analytical Chemistry): 0.590\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import pickle\n",
        "import logging\n",
        "from typing import List, Dict, Tuple\n",
        "import os\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class DeepLearningCareerRecommender:\n",
        "    def __init__(self, embedding_dim=128, hidden_layers=[256, 128, 64]):\n",
        "        \"\"\"\n",
        "        Initialize the Deep Learning Career Recommender\n",
        "\n",
        "        Args:\n",
        "            embedding_dim: Dimension of embedding vectors\n",
        "            hidden_layers: List of hidden layer sizes\n",
        "        \"\"\"\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_layers = hidden_layers\n",
        "        self.model = None\n",
        "        self.student_encoder = LabelEncoder()\n",
        "        self.course_encoder = LabelEncoder()\n",
        "        self.scaler = StandardScaler()\n",
        "        self.num_students = 0\n",
        "        self.num_courses = 0\n",
        "        self.feature_dim = 0\n",
        "\n",
        "    def prepare_features(self, students_df: pd.DataFrame, courses_df: pd.DataFrame) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Extract and engineer features from student and course data\n",
        "\n",
        "        Args:\n",
        "            students_df: DataFrame with student information\n",
        "            courses_df: DataFrame with course information\n",
        "\n",
        "        Returns:\n",
        "            Engineered features array\n",
        "        \"\"\"\n",
        "        features = []\n",
        "\n",
        "        # Subject performance features\n",
        "        subjects = ['Mathematics', 'Physics', 'Chemistry', 'Biology', 'English', 'Geography', 'History']\n",
        "\n",
        "        for _, student in students_df.iterrows():\n",
        "            student_features = []\n",
        "\n",
        "            # Parse subjects and create subject performance vector\n",
        "            student_subjects = student['subjects'].split(', ')\n",
        "            subject_vector = [1 if subj in student_subjects else 0 for subj in subjects]\n",
        "            student_features.extend(subject_vector)\n",
        "\n",
        "            # Parse interests and create interest categories\n",
        "            interests = student['interests'].split(', ')\n",
        "            interest_categories = {\n",
        "                'technology': ['programming', 'computers', 'innovation', 'AI', 'software', 'data', 'machine learning'],\n",
        "                'healthcare': ['medicine', 'nursing', 'biology', 'helping', 'health', 'medical'],\n",
        "                'business': ['entrepreneurship', 'marketing', 'finance', 'management', 'economics'],\n",
        "                'creative': ['art', 'design', 'music', 'writing', 'creative', 'media'],\n",
        "                'social': ['teaching', 'counseling', 'social work', 'psychology', 'education']\n",
        "            }\n",
        "\n",
        "            for category, keywords in interest_categories.items():\n",
        "                score = sum(1 for interest in interests\n",
        "                           if any(keyword.lower() in interest.lower() for keyword in keywords))\n",
        "                student_features.append(score)\n",
        "\n",
        "            # Academic performance indicators\n",
        "            stem_subjects = ['Mathematics', 'Physics', 'Chemistry', 'Biology']\n",
        "            stem_count = sum(1 for subj in student_subjects if subj in stem_subjects)\n",
        "            student_features.append(stem_count / len(stem_subjects))\n",
        "\n",
        "            humanities_subjects = ['English', 'Geography', 'History']\n",
        "            humanities_count = sum(1 for subj in student_subjects if subj in humanities_subjects)\n",
        "            student_features.append(humanities_count / len(humanities_subjects))\n",
        "\n",
        "            # Interest diversity\n",
        "            student_features.append(len(interests))\n",
        "\n",
        "            features.append(student_features)\n",
        "\n",
        "        return np.array(features)\n",
        "\n",
        "    def create_training_data(self, students_df: pd.DataFrame, courses_df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Create training data for the neural network\n",
        "\n",
        "        Args:\n",
        "            students_df: DataFrame with student information\n",
        "            courses_df: DataFrame with course information\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (student_ids, course_ids, features, ratings)\n",
        "        \"\"\"\n",
        "        # Encode student and course IDs\n",
        "        student_ids = self.student_encoder.fit_transform(students_df['student_id'])\n",
        "        course_ids = self.course_encoder.fit_transform(courses_df['course_name'])\n",
        "\n",
        "        self.num_students = len(student_ids)\n",
        "        self.num_courses = len(course_ids)\n",
        "\n",
        "        # Extract features\n",
        "        features = self.prepare_features(students_df, courses_df)\n",
        "        features = self.scaler.fit_transform(features)\n",
        "        self.feature_dim = features.shape[1]\n",
        "\n",
        "        # Create synthetic ratings based on subject-interest alignment\n",
        "        training_data = []\n",
        "\n",
        "        for i, student in students_df.iterrows():\n",
        "            student_subjects = set(student['subjects'].split(', '))\n",
        "            student_interests = set(student['interests'].split(', '))\n",
        "\n",
        "            for j, course in courses_df.iterrows():\n",
        "                course_subjects = set(course['subjects'].split(', '))\n",
        "                course_skills = set(course['skills'].split(', '))\n",
        "\n",
        "                # Calculate alignment score\n",
        "                subject_overlap = len(student_subjects.intersection(course_subjects))\n",
        "                interest_overlap = len(student_interests.intersection(course_skills))\n",
        "\n",
        "                # Create rating based on alignment (0-1 scale)\n",
        "                rating = (subject_overlap + interest_overlap) / (len(student_subjects) + len(student_interests))\n",
        "                rating = min(1.0, rating)  # Cap at 1.0\n",
        "\n",
        "                training_data.append({\n",
        "                    'student_id': i,\n",
        "                    'course_id': j,\n",
        "                    'features': features[i],\n",
        "                    'rating': rating\n",
        "                })\n",
        "\n",
        "        # Convert to arrays\n",
        "        training_df = pd.DataFrame(training_data)\n",
        "\n",
        "        return (\n",
        "            training_df['student_id'].values,\n",
        "            training_df['course_id'].values,\n",
        "            np.array(training_df['features'].tolist()),\n",
        "            training_df['rating'].values\n",
        "        )\n",
        "\n",
        "    def build_model(self):\n",
        "        \"\"\"\n",
        "        Build the neural network architecture\n",
        "        \"\"\"\n",
        "        # Input layers\n",
        "        student_input = layers.Input(shape=(), name='student_id')\n",
        "        course_input = layers.Input(shape=(), name='course_id')\n",
        "        features_input = layers.Input(shape=(self.feature_dim,), name='features')\n",
        "\n",
        "        # Embedding layers\n",
        "        student_embedding = layers.Embedding(\n",
        "            self.num_students,\n",
        "            self.embedding_dim,\n",
        "            embeddings_regularizer=tf.keras.regularizers.l2(0.01)\n",
        "        )(student_input)\n",
        "\n",
        "        course_embedding = layers.Embedding(\n",
        "            self.num_courses,\n",
        "            self.embedding_dim,\n",
        "            embeddings_regularizer=tf.keras.regularizers.l2(0.01)\n",
        "        )(course_input)\n",
        "\n",
        "        # Flatten embeddings\n",
        "        student_vec = layers.Flatten()(student_embedding)\n",
        "        course_vec = layers.Flatten()(course_embedding)\n",
        "\n",
        "        # Concatenate all features\n",
        "        combined = layers.concatenate([student_vec, course_vec, features_input])\n",
        "\n",
        "        # Deep layers with dropout and batch normalization\n",
        "        x = combined\n",
        "        for hidden_size in self.hidden_layers:\n",
        "            x = layers.Dense(hidden_size, activation='relu')(x)\n",
        "            x = layers.BatchNormalization()(x)\n",
        "            x = layers.Dropout(0.3)(x)\n",
        "\n",
        "        # Attention mechanism\n",
        "        attention = layers.Dense(self.hidden_layers[-1], activation='tanh')(x)\n",
        "        attention = layers.Dense(1, activation='sigmoid')(attention)\n",
        "        x = layers.multiply([x, attention])\n",
        "\n",
        "        # Output layer\n",
        "        output = layers.Dense(1, activation='sigmoid', name='rating')(x)\n",
        "\n",
        "        # Create model\n",
        "        model = Model(inputs=[student_input, course_input, features_input], outputs=output)\n",
        "\n",
        "        # Compile model\n",
        "        model.compile(\n",
        "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy', 'mae']\n",
        "        )\n",
        "\n",
        "        return model\n",
        "\n",
        "    def train(self, students_df: pd.DataFrame, courses_df: pd.DataFrame,\n",
        "              epochs=100, batch_size=256, validation_split=0.2):\n",
        "        \"\"\"\n",
        "        Train the deep learning model\n",
        "\n",
        "        Args:\n",
        "            students_df: DataFrame with student information\n",
        "            courses_df: DataFrame with course information\n",
        "            epochs: Number of training epochs\n",
        "            batch_size: Batch size for training\n",
        "            validation_split: Fraction of data for validation\n",
        "        \"\"\"\n",
        "        logger.info(\"Preparing training data...\")\n",
        "\n",
        "        # Create training data\n",
        "        student_ids, course_ids, features, ratings = self.create_training_data(students_df, courses_df)\n",
        "\n",
        "        # Build model\n",
        "        logger.info(\"Building neural network model...\")\n",
        "        self.model = self.build_model()\n",
        "\n",
        "        # Print model summary\n",
        "        self.model.summary()\n",
        "\n",
        "        # Callbacks\n",
        "        callbacks = [\n",
        "            EarlyStopping(\n",
        "                monitor='val_loss',\n",
        "                patience=15,\n",
        "                restore_best_weights=True,\n",
        "                verbose=1\n",
        "            ),\n",
        "            ReduceLROnPlateau(\n",
        "                monitor='val_loss',\n",
        "                factor=0.5,\n",
        "                patience=7,\n",
        "                min_lr=0.00001,\n",
        "                verbose=1\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        # Train model\n",
        "        logger.info(\"Training model...\")\n",
        "        history = self.model.fit(\n",
        "            [student_ids, course_ids, features],\n",
        "            ratings,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            validation_split=validation_split,\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        logger.info(\"Training completed!\")\n",
        "        return history\n",
        "\n",
        "    def predict_for_student(self, student_data: Dict, courses_df: pd.DataFrame, top_k=5) -> List[Tuple[str, float]]:\n",
        "        \"\"\"\n",
        "        Predict career recommendations for a single student\n",
        "\n",
        "        Args:\n",
        "            student_data: Dictionary with 'subjects' and 'interests' keys\n",
        "            courses_df: DataFrame with course information\n",
        "            top_k: Number of top recommendations to return\n",
        "\n",
        "        Returns:\n",
        "            List of (course_name, confidence_score) tuples\n",
        "        \"\"\"\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model not trained yet!\")\n",
        "\n",
        "        # Create a temporary DataFrame for the student\n",
        "        temp_student_df = pd.DataFrame([{\n",
        "            'student_id': 'temp_student',\n",
        "            'subjects': ', '.join(student_data['subjects']),\n",
        "            'interests': ', '.join(student_data['interests'])\n",
        "        }])\n",
        "\n",
        "        # Extract features for the student\n",
        "        student_features = self.prepare_features(temp_student_df, courses_df)\n",
        "        student_features = self.scaler.transform(student_features)\n",
        "\n",
        "        # Predict for all courses\n",
        "        predictions = []\n",
        "\n",
        "        for idx, course in courses_df.iterrows():\n",
        "            # Use a dummy student ID (encoded as 0)\n",
        "            student_id = np.array([0])\n",
        "\n",
        "            # Encode course ID\n",
        "            if course['course_name'] in self.course_encoder.classes_:\n",
        "                course_id = self.course_encoder.transform([course['course_name']])[0]\n",
        "            else:\n",
        "                # Handle unseen courses\n",
        "                course_id = 0\n",
        "\n",
        "            course_id = np.array([course_id])\n",
        "\n",
        "            # Predict rating\n",
        "            rating = self.model.predict([student_id, course_id, student_features], verbose=0)[0][0]\n",
        "\n",
        "            predictions.append((course['course_name'], float(rating)))\n",
        "\n",
        "        # Sort by rating and return top K\n",
        "        predictions.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        return predictions[:top_k]\n",
        "\n",
        "    def save_model(self, filepath: str):\n",
        "        \"\"\"Save the trained model and preprocessors\"\"\"\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"No model to save!\")\n",
        "\n",
        "        # Save model\n",
        "        self.model.save(f\"{filepath}_model.h5\")\n",
        "\n",
        "        # Save preprocessors\n",
        "        with open(f\"{filepath}_preprocessors.pkl\", 'wb') as f:\n",
        "            pickle.dump({\n",
        "                'student_encoder': self.student_encoder,\n",
        "                'course_encoder': self.course_encoder,\n",
        "                'scaler': self.scaler,\n",
        "                'num_students': self.num_students,\n",
        "                'num_courses': self.num_courses,\n",
        "                'feature_dim': self.feature_dim,\n",
        "                'embedding_dim': self.embedding_dim,\n",
        "                'hidden_layers': self.hidden_layers\n",
        "            }, f)\n",
        "\n",
        "        logger.info(f\"Model saved to {filepath}\")\n",
        "\n",
        "    def load_model(self, filepath: str):\n",
        "        \"\"\"Load a trained model and preprocessors\"\"\"\n",
        "        # Load model\n",
        "        self.model = tf.keras.models.load_model(f\"{filepath}_model.h5\")\n",
        "\n",
        "        # Load preprocessors\n",
        "        with open(f\"{filepath}_preprocessors.pkl\", 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "            self.student_encoder = data['student_encoder']\n",
        "            self.course_encoder = data['course_encoder']\n",
        "            self.scaler = data['scaler']\n",
        "            self.num_students = data['num_students']\n",
        "            self.num_courses = data['num_courses']\n",
        "            self.feature_dim = data['feature_dim']\n",
        "            self.embedding_dim = data['embedding_dim']\n",
        "            self.hidden_layers = data['hidden_layers']\n",
        "\n",
        "        logger.info(f\"Model loaded from {filepath}\")\n",
        "\n",
        "# Example usage and training script\n",
        "def main():\n",
        "    # Load data\n",
        "    students_df = pd.read_csv('./sample_data/student_data.csv', on_bad_lines='skip')\n",
        "    courses_df = pd.read_csv('./sample_data/Courses.csv')\n",
        "\n",
        "    # Initialize recommender\n",
        "    recommender = DeepLearningCareerRecommender(\n",
        "        embedding_dim=128,\n",
        "        hidden_layers=[256, 128, 64]\n",
        "    )\n",
        "\n",
        "    # Train model\n",
        "    history = recommender.train(\n",
        "        students_df,\n",
        "        courses_df,\n",
        "        epochs=50,\n",
        "        batch_size=128\n",
        "    )\n",
        "\n",
        "    # Save model\n",
        "    recommender.save_model('deep_learning_career_model')\n",
        "\n",
        "    # Test prediction\n",
        "    test_student = {\n",
        "        'subjects': ['Mathematics', 'Physics'],\n",
        "        'interests': ['Artificial Intelligence', 'Machine Learning']\n",
        "    }\n",
        "\n",
        "    recommendations = recommender.predict_for_student(test_student, courses_df)\n",
        "\n",
        "    print(\"Recommendations for test student:\")\n",
        "    for course, confidence in recommendations:\n",
        "        print(f\"  {course}: {confidence:.3f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}